"""
FastAPI application for the AI Sales Query Agent.

Exposes a POST /query endpoint that accepts natural language questions
and returns SQL results using the MCP server and LLM agent.
"""

import logging

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field

from agent.sql_agent import process_question

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI app
app = FastAPI(
    title="AI Sales Query Agent",
    description=(
        "A FastAPI service that translates natural language questions "
        "into SQL queries against a SQLite sales database. "
        "Uses MCP (Model Context Protocol) for secure data access "
        "and LangChain for SQL generation."
    ),
    version="1.0.0",
)


# --- Pydantic Models ---


class QueryRequest(BaseModel):
    """Request body for the /query endpoint."""

    question: str = Field(
        ...,
        description="A natural language question about the sales data.",
        min_length=1,
        examples=["What is the total number of customers?"],
    )


class ChartData(BaseModel):
    """Simplified chart-friendly data format."""

    labels: list[str] = Field(default_factory=list, description="Chart labels (category axis).")
    values: list[float] = Field(default_factory=list, description="Chart values (numeric axis).")


class QueryResponse(BaseModel):
    """Response body for the /query endpoint."""

    sql: str = Field(..., description="The SQL query generated by the LLM.")
    results: list[dict] = Field(default_factory=list, description="Query result rows as list of objects.")
    chart_data: ChartData = Field(default_factory=ChartData, description="Chart-friendly data.")


class ErrorResponse(BaseModel):
    """Error response body."""

    detail: str = Field(..., description="Error message explaining what went wrong.")


# --- Endpoints ---


@app.get("/", tags=["Health"])
async def root():
    """Health check / welcome endpoint."""
    return {
        "service": "AI Sales Query Agent",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs",
    }


@app.post(
    "/query",
    response_model=QueryResponse,
    responses={
        400: {"model": ErrorResponse, "description": "Invalid or unanswerable question"},
        500: {"model": ErrorResponse, "description": "Internal server error"},
    },
    tags=["Query"],
)
async def query_endpoint(request: QueryRequest):
    """Translate a natural language question into SQL and return results.

    The agent will:
    1. Inspect the database schema via MCP tools
    2. Generate a SQL query using an LLM (Claude / Groq / Ollama)
    3. Execute the query against the sales database
    4. Return the SQL, results, and chart-friendly data
    """
    logger.info(f"Received question: {request.question}")

    try:
        result = process_question(request.question)

        response = QueryResponse(
            sql=result["sql"],
            results=result["results"],
            chart_data=ChartData(**result["chart_data"]),
        )

        logger.info(f"Generated SQL: {response.sql}")
        logger.info(f"Returned {len(response.results)} rows")

        return response

    except ValueError as e:
        # Unanswerable questions, invalid SQL, security violations
        logger.warning(f"Bad request: {e}")
        raise HTTPException(status_code=400, detail=str(e))

    except RuntimeError as e:
        # No LLM provider available
        logger.error(f"Runtime error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

    except Exception as e:
        # Unexpected errors
        logger.error(f"Unexpected error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Internal server error: {e}")
